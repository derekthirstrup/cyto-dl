# TensorRT Dynamic Shapes Configuration
# Allows variable batch sizes (slightly slower than fixed shapes)

# TensorRT export settings
tensorrt:
  enabled: True
  precision: fp16
  workspace_size: 4  # GB
  dynamic_shapes: True  # Enable dynamic batch sizes

  # Batch size range
  min_batch_size: 1
  max_batch_size: 32
  opt_batch_size: 8  # Optimize for this batch size

# Use optimized inference trainer
defaults:
  - override /trainer: gpu_optimized
  - override /performance: gpu_optimized

# Inference-specific trainer settings
trainer:
  precision: bf16-mixed

# Model settings
model:
  compile_model: False
  channels_last: True
  inference_args:
    sw_batch_size: 8
    mode: gaussian
